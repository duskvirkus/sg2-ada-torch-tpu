{
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 2.7.17 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Python 3.7.10\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 1)) (0.10)\n",
      "Requirement already satisfied: torch-xla==1.9 from https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 2)) (1.9)\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (4.1.3)\n",
      "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (0.17.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (4.7.2)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (0.0.4)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (1.26.3)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (1.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (1.53.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (2.23.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (2018.9)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (57.0.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (20.9)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (3.12.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (1.24.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10->-r ../requirements.txt (line 1)) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required: definitely edit these!\n",
    "dataset_path = './datasets/warhol-001-data.zip'\n",
    "resume_from = 'ffhq1024'\n",
    "aug_strength = 0.0\n",
    "train_count = 0\n",
    "mirror_x = False\n",
    "mirror_y = False\n",
    "\n",
    "#optional: you might not need to edit these\n",
    "gamma_value = 50.0\n",
    "augs = 'bgc'\n",
    "config = 'tpu-colab'\n",
    "snapshot_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.9...\n",
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.9...\n",
      "WARNING:root:TPU has started up successfully with version pytorch-1.9\n",
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
      "Usage: train.py [OPTIONS]\n",
      "\n",
      "  Train a GAN using the techniques described in\n",
      "  the paper \"Training Generative Adversarial\n",
      "  Networks with Limited Data\".\n",
      "\n",
      "  Examples:\n",
      "\n",
      "  # Train with custom dataset using 1 GPU.\n",
      "  python train.py --outdir=~/training-runs --data=~/mydataset.zip --gpus=1\n",
      "\n",
      "  # Train class-conditional CIFAR-10 using 2 GPUs.\n",
      "  python train.py --outdir=~/training-runs --data=~/datasets/cifar10.zip \\\n",
      "      --gpus=2 --cfg=cifar --cond=1\n",
      "\n",
      "  # Transfer learn MetFaces from FFHQ using 4 GPUs.\n",
      "  python train.py --outdir=~/training-runs --data=~/datasets/metfaces.zip \\\n",
      "      --gpus=4 --cfg=paper1024 --mirror=1 --resume=ffhq1024 --snap=10\n",
      "\n",
      "  # Reproduce original StyleGAN2 config F.\n",
      "  python train.py --outdir=~/training-runs --data=~/datasets/ffhq.zip \\\n",
      "      --gpus=8 --cfg=stylegan2 --mirror=1 --aug=noaug\n",
      "\n",
      "  Base configs (--cfg):\n",
      "    auto       Automatically select reasonable defaults based on resolution\n",
      "               and GPU count. Good starting point for new datasets.\n",
      "    stylegan2  Reproduce results for StyleGAN2 config F at 1024x1024.\n",
      "    paper256   Reproduce results for FFHQ and LSUN Cat at 256x256.\n",
      "    paper512   Reproduce results for BreCaHAD and AFHQ at 512x512.\n",
      "    paper1024  Reproduce results for MetFaces at 1024x1024.\n",
      "    cifar      Reproduce results for CIFAR-10 at 32x32.\n",
      "\n",
      "  Transfer learning source networks (--resume):\n",
      "    ffhq256        FFHQ trained at 256x256 resolution.\n",
      "    ffhq512        FFHQ trained at 512x512 resolution.\n",
      "    ffhq1024       FFHQ trained at 1024x1024 resolution.\n",
      "    celebahq256    CelebA-HQ trained at 256x256 resolution.\n",
      "    lsundog256     LSUN Dog trained at 256x256 resolution.\n",
      "    <PATH or URL>  Custom network pickle.\n",
      "\n",
      "Options:\n",
      "  --outdir DIR                    Where to save\n",
      "                                  the results\n",
      "                                  [required]\n",
      "\n",
      "  --gpus INT                      Number of GPUs\n",
      "                                  to use [default:\n",
      "                                  1]\n",
      "\n",
      "  --tpus INT                      Number of TPUs\n",
      "                                  to use.\n",
      "                                  Incompatable\n",
      "                                  with gpu useage.\n",
      "                                  --gpus will be\n",
      "                                  ignored if this\n",
      "                                  arugment is\n",
      "                                  passed.\n",
      "                                  [default: None]\n",
      "\n",
      "  --snap INT                      Snapshot\n",
      "                                  interval\n",
      "                                  [default: 50\n",
      "                                  ticks]\n",
      "\n",
      "  --metrics LIST                  Comma-separated\n",
      "                                  list or \"none\"\n",
      "                                  [default:\n",
      "                                  fid50k_full]\n",
      "\n",
      "  --seed INT                      Random seed\n",
      "                                  [default: 0]\n",
      "\n",
      "  -n, --dry-run                   Print training\n",
      "                                  options and exit\n",
      "\n",
      "  --data PATH                     Training data\n",
      "                                  (directory or\n",
      "                                  zip)  [required]\n",
      "\n",
      "  --cond BOOL                     Train\n",
      "                                  conditional\n",
      "                                  model based on\n",
      "                                  dataset labels\n",
      "                                  [default: false]\n",
      "\n",
      "  --subset INT                    Train with only\n",
      "                                  N images\n",
      "                                  [default: all]\n",
      "\n",
      "  --mirror BOOL                   Enable dataset\n",
      "                                  x-flips\n",
      "                                  [default: false]\n",
      "\n",
      "  --mirrory BOOL                  Augment dataset\n",
      "                                  with y-flips\n",
      "                                  (default: false)\n",
      "\n",
      "  --cfg [auto|11gb-gpu|11gb-gpu-complex|24gb-gpu|24gb-gpu-complex|48gb-gpu|48gb-2gpu|stylegan2|paper256|paper512|paper1024|cifar|cifarbaseline|aydao|tpu-colab]\n",
      "                                  Base config\n",
      "                                  [default: auto]\n",
      "\n",
      "  --lrate FLOAT                   Override\n",
      "                                  learning rate\n",
      "\n",
      "  --gamma FLOAT                   Override R1\n",
      "                                  gamma\n",
      "\n",
      "  --kimg INT                      Override\n",
      "                                  training\n",
      "                                  duration\n",
      "\n",
      "  --nkimg INT                     Override\n",
      "                                  starting count\n",
      "\n",
      "  --batch INT                     Override batch\n",
      "                                  size\n",
      "\n",
      "  --aug [noaug|ada|fixed]         Augmentation\n",
      "                                  mode [default:\n",
      "                                  ada]\n",
      "\n",
      "  --p FLOAT                       Augmentation\n",
      "                                  probability for\n",
      "                                  --aug=fixed\n",
      "\n",
      "  --target FLOAT                  ADA target value\n",
      "                                  for --aug=ada\n",
      "\n",
      "  --augpipe [blit|geom|color|filter|noise|cutout|bg|bgc|bgcf|bgcfn|bgcfnc]\n",
      "                                  Augmentation\n",
      "                                  pipeline\n",
      "                                  [default: bgc]\n",
      "\n",
      "  --initstrength FLOAT            Override ADA\n",
      "                                  strength at\n",
      "                                  start\n",
      "\n",
      "  --resume PKL                    Resume training\n",
      "                                  [default:\n",
      "                                  noresume]\n",
      "\n",
      "  --freezed INT                   Freeze-D\n",
      "                                  [default: 0\n",
      "                                  layers]\n",
      "\n",
      "  --fp32 BOOL                     Disable mixed-\n",
      "                                  precision\n",
      "                                  training\n",
      "\n",
      "  --nhwc BOOL                     Use NHWC memory\n",
      "                                  format with FP16\n",
      "\n",
      "  --nobench BOOL                  Disable cuDNN\n",
      "                                  benchmarking\n",
      "\n",
      "  --allow-tf32 BOOL               Allow PyTorch to\n",
      "                                  use TF32\n",
      "                                  internally\n",
      "\n",
      "  --workers INT                   Override number\n",
      "                                  of DataLoader\n",
      "                                  workers\n",
      "\n",
      "  --help                          Show this\n",
      "                                  message and\n",
      "                                  exit.\n"
     ]
    }
   ],
   "source": [
    "!python3 ../train.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:root:TPU has started up successfully with version pytorch-1.9\n",
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"num_tpus\": 8,\n",
      "  \"image_snapshot_ticks\": 1,\n",
      "  \"network_snapshot_ticks\": 1,\n",
      "  \"metrics\": [],\n",
      "  \"random_seed\": 0,\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"./datasets/warhol-001-data.zip\",\n",
      "    \"use_labels\": false,\n",
      "    \"max_size\": 2,\n",
      "    \"xflip\": false,\n",
      "    \"resolution\": 1024\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"num_workers\": 3,\n",
      "    \"prefetch_factor\": 2\n",
      "  },\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 8\n",
      "    },\n",
      "    \"synthesis_kwargs\": {\n",
      "      \"channel_base\": 32768,\n",
      "      \"channel_max\": 512,\n",
      "      \"num_fp16_res\": 4,\n",
      "      \"conv_clamp\": 256\n",
      "    }\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Discriminator\",\n",
      "    \"block_kwargs\": {},\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 32768,\n",
      "    \"channel_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.002,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.002,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 50.0\n",
      "  },\n",
      "  \"total_kimg\": 25000,\n",
      "  \"batch_size\": 32,\n",
      "  \"batch_gpu\": 4,\n",
      "  \"ema_kimg\": 10,\n",
      "  \"ema_rampup\": null,\n",
      "  \"nimg\": 0,\n",
      "  \"ada_target\": 0.6,\n",
      "  \"augment_p\": 0.0,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"resume_pkl\": \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/transfer-learning-source-nets/ffhq-res1024-mirror-stylegan2-noaug.pkl\",\n",
      "  \"ada_kimg\": 100,\n",
      "  \"run_dir\": \"./results/00016-warhol-001-data-tpu-colab-gamma50-bgc-resumeffhq1024\"\n",
      "}\n",
      "\n",
      "Output directory:   ./results/00016-warhol-001-data-tpu-colab-gamma50-bgc-resumeffhq1024\n",
      "Training data:      ./datasets/warhol-001-data.zip\n",
      "Training duration:  25000 kimgs\n",
      "Number of TPUs:     8\n",
      "Number of images:   2\n",
      "Image resolution:   1024\n",
      "Conditional model:  False\n",
      "Dataset x-flips:    False\n",
      "\n",
      "Creating output directory...\n",
      "Launching processes...\n",
      "Loading training set...\n",
      "\n",
      "Num images:  2\n",
      "Image shape: [3, 1024, 1024]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Resuming from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/transfer-learning-source-nets/ffhq-res1024-mirror-stylegan2-noaug.pkl\"\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/transfer-learning-source-nets/ffhq-res1024-mirror-stylegan2-noaug.pkl ...Exception in device=TPU:3: Error initializing torch.distributed using env:// rendezvous: environment variable MASTER_ADDR expected, but not set\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n",
      "    _start_fn(index, pf_cfg, fn, args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n",
      "    fn(gindex, *args)\n",
      "  File \"../train.py\", line 435, in subprocess_fn\n",
      "    training_loop.training_loop(rank=rank, **args)\n",
      "  File \"/content/drive/MyDrive/colab-sg2-ada-torch-tpu-devel/sg2-ada-torch-tpu/training/training_loop.py\", line 240, in training_loop\n",
      "    torch.distributed.init_process_group(\"gloo\", rank=xm.get_ordinal(), world_size=xm.xrt_world_size())\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/distributed_c10d.py\", line 520, in init_process_group\n",
      "    store, rank, world_size = next(rendezvous_iterator)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/rendezvous.py\", line 182, in _env_rendezvous_handler\n",
      "    master_addr = _get_env_or_raise(\"MASTER_ADDR\")\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/rendezvous.py\", line 159, in _get_env_or_raise\n",
      "    raise _env_error(env_var)\n",
      "ValueError: Error initializing torch.distributed using env:// rendezvous: environment variable MASTER_ADDR expected, but not set\n",
      "Traceback (most recent call last):\n",
      "  File \"../train.py\", line 604, in <module>\n",
      "    main() # pylint: disable=no-value-for-parameter\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
      "    return callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/click/decorators.py\", line 21, in new_func\n",
      "    return f(get_current_context(), *args, **kwargs)\n",
      "  File \"../train.py\", line 593, in main\n",
      "    xmp.spawn(subprocess_fn, args=(args, temp_dir), nprocs=args.num_tpus, start_method='fork')\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 394, in spawn\n",
      "    start_method=start_method)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 188, in start_processes\n",
      "    while not context.join():\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 144, in join\n",
      "    exit_code=exitcode\n",
      "torch.multiprocessing.spawn.ProcessExitedException: process 3 terminated with exit code 17\n"
     ]
    }
   ],
   "source": [
    "!python3 ../train.py --tpus=8 --cfg=$config --metrics=None --outdir=./results --data=$dataset_path --snap=$snapshot_count --resume=$resume_from --augpipe=$augs --initstrength=$aug_strength --gamma=$gamma_value --mirror=$mirror_x --mirrory=False --nkimg=$train_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}